{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import Select   # seleccion de un dropdown\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.common.exceptions import TimeoutException\n",
    "# import time\n",
    "\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# import multiprocessing as mp\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# from joblib._parallel_backends import LokyBackend\n",
    "# import asyncio\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "# from datetime import datetime, timedelta\n",
    "# import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b96a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################################################################################################################\n",
    "# url = 'https://en.tutiempo.net/madrid-barajas.html?data=hourly&v=list'\n",
    "\n",
    "# driver = webdriver.Chrome()\n",
    "# driver.get(url)\n",
    "# wait = WebDriverWait(driver, 5) #\n",
    "\n",
    "# # Esperar a que aparezca el botón de aceptar normas\n",
    "# normas_button_xpath = '/html/body/div[16]/div[2]/div[1]/div[2]/div[2]/button[1]/p'\n",
    "# normas_button_xpath2 = '/html/body/div[18]/div[2]/div[1]/div[2]/div[2]/button[1]/p'\n",
    "# try:\n",
    "#     wait.until(EC.element_to_be_clickable((By.XPATH, normas_button_xpath)))\n",
    "#     normas_button = driver.find_element(By.XPATH, normas_button_xpath)\n",
    "#     normas_button.click()\n",
    "# except:\n",
    "#     wait.until(EC.element_to_be_clickable((By.XPATH, normas_button_xpath2)))\n",
    "#     normas_button = driver.find_element(By.XPATH, normas_button_xpath2)\n",
    "#     normas_button.click()\n",
    "# print(\"Aceptado normas\")\n",
    "\n",
    "# # Esperar a que aparezca el botón de aceptar cookies\n",
    "# cookies_button_xpath = '//*[@id=\"DivAceptarCookies\"]/div/a[2]'\n",
    "# wait.until(EC.element_to_be_clickable((By.XPATH, cookies_button_xpath)))\n",
    "# cookies_button = driver.find_element(By.XPATH, cookies_button_xpath)\n",
    "# cookies_button.click()\n",
    "# print(\"Aceptadas cookies\")\n",
    "        \n",
    "# # Esperar a que cargue la página (usando un elemento en la tabla como referencia)\n",
    "# wait.until(EC.presence_of_element_located((By.XPATH, '//table//tbody//tr[3]')))\n",
    "# print(\"Página cargada\")\n",
    "\n",
    "# day = driver.find_elements(By.XPATH, '//table//tbody//tr')[1].text\n",
    "\n",
    "# time.sleep(5)\n",
    "\n",
    "# table = [row.text.split('\\n')[0:4]+ row.text.split('\\n')[-1].split(' ')\n",
    "#  for row in driver.find_elements(By.XPATH, '//table//tbody//tr')[6::]\n",
    "# ]  # Copia los registros\n",
    "# print(\"Registros extraídos\")\n",
    "# driver.quit()\n",
    "\n",
    "# #################################################################################################################\n",
    "# # Encontrar el índice de la primera sublista que comienza con 'Tomorrow'\n",
    "# indice_inicio = next(i for i, sublist in enumerate(table) if sublist[0].startswith('Tomorrow'))\n",
    "\n",
    "# # Seleccionar las 25 sublistas a partir del índice encontrado\n",
    "# lista_filtrada = table[indice_inicio:indice_inicio + 26]\n",
    "\n",
    "# columns = ['Hour', 'Condition', 'Temperature','Wind', 'Relative_hum','Clouds','AP','1']\n",
    "# mt = pd.DataFrame(lista_filtrada[2:], columns=columns)\n",
    "# mt.loc[mt['Condition'].str.lower().str.contains('rain'), 'Condition'] = 'Rain'\n",
    "# mt = mt [['Hour','Condition','Temperature', 'Wind']]\n",
    "# mt['Temperature'] = pd.to_numeric(mt['Temperature'].str[:-1])\n",
    "# mt['Wind'] = pd.to_numeric(mt['Wind'].str[:-5])\n",
    "# #################################################################################################################\n",
    "# def obtener_fecha_manana():\n",
    "#     # Obtener la fecha actual\n",
    "#     fecha_actual = datetime.now()\n",
    "\n",
    "#     # Calcular la fecha del día siguiente\n",
    "#     fecha_manana = fecha_actual + timedelta(days=1)\n",
    "\n",
    "#     # Formatear la fecha como \"YYYY-MM-DD\"\n",
    "#     formato_fecha = fecha_manana.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#     return formato_fecha\n",
    "\n",
    "# # Obtengo fecha del día siguiente\n",
    "# tomorrow = obtener_fecha_manana()\n",
    "\n",
    "# url = f'https://www.flightera.net/en/airport/Madrid/LEMD/departure/{tomorrow}%2000_00'\n",
    "# # url\n",
    "\n",
    "# table2 = []  # Inicializa table como una lista vacía\n",
    "# #Columnas tras la extracción\n",
    "# #columns = [\"bad_date\",\"1\", \"status\",\"cod_flight\",\"airliner\", \"destiny\", \"depart\",\"delay_d\",\"8\",\"arrival\",\"delay_a\",\"duration\",\"12\"]  # Añade las columnas\n",
    "# #Fecha de la URL\n",
    "\n",
    "# match = re.search(r'\\d{4}-\\d{2}-\\d{2}', url)\n",
    "# match = match.group()\n",
    "# match\n",
    "# try:\n",
    "#     #Opciones\n",
    "#     opciones=Options()\n",
    "#     opciones.add_extension('drivers/adblock.crx')       # adblocker\n",
    "#     opciones.add_argument('cookies=cookies')    # man\n",
    "# #         opciones.add_argument(f'--load-extension={drivers/adblock.crx}')\n",
    "#     #Inicializo el drive\n",
    "#     driver = webdriver.Chrome(options=opciones)\n",
    "#     driver.get(url)\n",
    "#     wait = WebDriverWait(driver, 20)\n",
    "#     time.sleep(35)\n",
    "\n",
    "#     #Aceptar cookies\n",
    "\n",
    "#     aceptar = driver.find_element(By.XPATH,'//*[@id=\"qc-cmp2-ui\"]/div[2]/div/button[2]')\n",
    "#     aceptar.click()\n",
    "\n",
    "#     # Extraer la información la primera vez\n",
    "#     table2 += [flight.text.split('\\n') for flight in driver.find_elements(By.XPATH, '//table//tbody//tr')[1:]]\n",
    "#     time.sleep(2)\n",
    "\n",
    "#     # Clickar en el botón Later Flights para abrir una nueva URL\n",
    "#     aceptar = wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/main/div[6]/div[2]/a')))\n",
    "#     #aceptar = driver.find_element(By.XPATH, '/html/body/div[3]/main/div[6]/div[2]/a')\n",
    "#     aceptar.click()\n",
    "#     time.sleep(2)\n",
    "\n",
    "#     # Clickar en boton popup \n",
    "#     aceptar2 = driver.find_element(By.XPATH, '/html/body/div[9]/div/div/div/div/div/div[3]/span[1]/button')\n",
    "#     aceptar2.click()\n",
    "#     time.sleep(2)\n",
    "    \n",
    "#     # Extraer la información la primera vez\n",
    "#     table2 += [flight.text.split('\\n') for flight in driver.find_elements(By.XPATH, '//table//tbody//tr')[1:]]\n",
    "#     time.sleep(2)\n",
    "    \n",
    "#     aceptar = driver.find_element(By.XPATH,'/html/body/div[2]/main/div[6]/div[2]/a')\n",
    "#     aceptar.click()\n",
    "#     time.sleep(2)\n",
    "#     # Bucle while hasta que la fecha de cada link desaparezca de la URL\n",
    "\n",
    "#     while match in driver.current_url:\n",
    "#         try:\n",
    "#             #Extraer datos\n",
    "#             table2 += [flight.text.split('\\n') for flight in driver.find_elements(By.XPATH, '//table//tbody//tr')[1:]]\n",
    "#             # Clickar en el botón Later Flights para abrir una nueva URL\n",
    "#             aceptar = driver.find_element(By.XPATH,'/html/body/div[2]/main/div[6]/div[2]/a')\n",
    "#             aceptar.click()\n",
    "\n",
    "#         except:\n",
    "#             # Clickar en boton popup si aparece\n",
    "#             aceptar2 = driver.find_element(By.XPATH,'/html/body/div[9]/div/div/div/div/div/div[3]/span[1]/button')\n",
    "#             aceptar2.click()       \n",
    "\n",
    "# #     return table  # Devuelve un DataFrame con los datos de ese día \n",
    "\n",
    "# except:\n",
    "#     print(\"Extraction Failed\")\n",
    "# finally:\n",
    "#     print(\"Extraction completed\")\n",
    "#     driver.quit()\n",
    "# #################################################################################################################\n",
    "# # Genero el Dataframe\n",
    "# columns = ['Date','1','Status', 'code','airliner' ,'mix_data1','mix_data2']\n",
    "# fl = pd.DataFrame(table2, columns=columns)\n",
    "\n",
    "# # Elimino nulos\n",
    "# fl = fl.dropna() \n",
    "\n",
    "# # Me quedo solo con los vuelos del día de mañana\n",
    "# fl = fl[fl.Date == fl.Date.loc[0]] \n",
    "\n",
    "# # Convierte la columna 'Date' al formato de fecha\n",
    "# fl['Date'] = pd.to_datetime(fl['Date'] + ' 2023', format='%a, %d. %b %Y')\n",
    "# # Genera la columna 'week_day' con el día de la semana en inglés\n",
    "# fl['week_day'] = fl['Date'].dt.strftime('%A')\n",
    "# # Genera la columna 'week_num' con el número de la semana (considerando que los registros son de 2023)\n",
    "# fl['week_num'] = fl['Date'].dt.strftime('%U')\n",
    "# fl = fl.drop_duplicates(keep='first')\n",
    "# fl['code'] = fl['code'].str.split().str[0]\n",
    "# # Genero columnas con el código de la aerolínea, del aeropuerto y la hora\n",
    "# fl['cod_airliner_IATA'] = fl['mix_data1'].str.extract(r'(\\b\\w{2})')\n",
    "# fl['cod_airport_IATA'] = fl['mix_data1'].str.extract(r'\\(\\s*(\\b\\w{3})\\s*/')  # Modificación aquí\n",
    "# fl['hora'] = fl['mix_data1'].str.extract(r'(\\d{2}:\\d{2})')\n",
    "\n",
    "# # Aplicar la función a la columna mix_data2 y almacenar los resultados en la columna duration\n",
    "# fl['duration'] = fl['mix_data2'].apply(obtener_duracion_vuelo)\n",
    "# # Redondear la duración total a la unidad de horas\n",
    "# fl['duration'] = fl['duration'].apply(lambda x: max(round(x / 60), 1))\n",
    "\n",
    "# columnas_a_eliminar = ['Date','1','airliner', 'mix_data1', 'mix_data2']\n",
    "# fl = fl.drop(columnas_a_eliminar, axis=1)\n",
    "# fl = fl.rename(columns ={'Status':'status', 'hora':'hour', \"code\": \"cod_flight_IATA\"})\n",
    "\n",
    "# mt = mt.rename(columns = {'Hour':'hour'})\n",
    "\n",
    "# fl['hour'] = pd.to_datetime(fl['hour'], format='%H:%M').dt.time\n",
    "# mt['hour'] = pd.to_datetime(mt['hour'], format='%H:%M').dt.time\n",
    "\n",
    "# # Convertir la columna 'hour' a tipo de datos timedelta en ambos DataFrames\n",
    "# mt['hour'] = pd.to_timedelta(mt['hour'].astype(str))\n",
    "# fl['hour'] = pd.to_timedelta(fl['hour'].astype(str))\n",
    "\n",
    "# # Calcular la cantidad total de segundos desde la medianoche\n",
    "# mt['seconds_since_midnight'] = mt['hour'].dt.total_seconds()\n",
    "# fl['seconds_since_midnight'] = fl['hour'].dt.total_seconds()\n",
    "\n",
    "# # Ordenar ambos DataFrames por la columna 'seconds_since_midnight'\n",
    "# mt = mt.sort_values('seconds_since_midnight')\n",
    "# fl = fl.sort_values('seconds_since_midnight')\n",
    "\n",
    "# # Realizar la fusión en la dirección contraria ('backward')\n",
    "# fl = pd.merge_asof(fl, mt, on='seconds_since_midnight', direction='backward')\n",
    "\n",
    "# # Eliminar la columna temporal agregada para la fusión\n",
    "# fl = fl.drop(columns='seconds_since_midnight')\n",
    "# fl.head()\n",
    "\n",
    "# # Convertir la columna 'hour_x' al formato de tiempo\n",
    "# fl['hour_x'] = pd.to_timedelta(fl['hour_x'])\n",
    "\n",
    "# # Extraer solo la parte de la hora\n",
    "# fl['hour_x'] = fl['hour_x'].apply(lambda x: '{:02}:{:02}:{:02}'.format(int(x.total_seconds() // 3600), int((x.total_seconds() % 3600) // 60), int(x.total_seconds() % 60)))\n",
    "# fl.head()\n",
    "\n",
    "# fl = fl[['status', 'cod_flight_IATA', 'week_day', 'week_num',\n",
    "#        'cod_airliner_IATA', 'cod_airport_IATA', 'hour_x', 'duration',\n",
    "#        'Condition', 'Temperature', 'Wind']]\n",
    "# fl = fl.rename(columns = {'hour_x':'hour'})\n",
    "# fl['hour'] = pd.to_datetime(fl['hour'])\n",
    "# fl['day_time'] = pd.cut(fl['hour'].dt.hour,\n",
    "#                                bins=[0, 6, 12, 18, 24],\n",
    "#                                labels=['Early Morning', 'Morning', 'Afternoon', 'Night'],\n",
    "#                                right=False)\n",
    "# fl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db668867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_tutiempo_data():\n",
    "#     # Inicializar el driver de Chrome\n",
    "#     url = 'https://en.tutiempo.net/madrid-barajas.html?data=hourly&v=list'\n",
    "#     driver = webdriver.Chrome()\n",
    "#     driver.get(url)\n",
    "#     wait = WebDriverWait(driver, 5)\n",
    "\n",
    "#     # Esperar a que aparezca el botón de aceptar normas\n",
    "#     normas_button_xpath = '/html/body/div[16]/div[2]/div[1]/div[2]/div[2]/button[1]/p'\n",
    "#     normas_button_xpath2 = '/html/body/div[18]/div[2]/div[1]/div[2]/div[2]/button[1]/p'\n",
    "    \n",
    "#     try:\n",
    "#         wait.until(EC.element_to_be_clickable((By.XPATH, normas_button_xpath)))\n",
    "#         normas_button = driver.find_element(By.XPATH, normas_button_xpath)\n",
    "#         normas_button.click()\n",
    "#     except:\n",
    "#         wait.until(EC.element_to_be_clickable((By.XPATH, normas_button_xpath2)))\n",
    "#         normas_button = driver.find_element(By.XPATH, normas_button_xpath2)\n",
    "#         normas_button.click()\n",
    "    \n",
    "#     print(\"Aceptado normas\")\n",
    "\n",
    "#     # Esperar a que aparezca el botón de aceptar cookies\n",
    "#     cookies_button_xpath = '//*[@id=\"DivAceptarCookies\"]/div/a[2]'\n",
    "#     wait.until(EC.element_to_be_clickable((By.XPATH, cookies_button_xpath)))\n",
    "#     cookies_button = driver.find_element(By.XPATH, cookies_button_xpath)\n",
    "#     cookies_button.click()\n",
    "    \n",
    "#     print(\"Aceptadas cookies\")\n",
    "\n",
    "#     # Esperar a que cargue la página (usando un elemento en la tabla como referencia)\n",
    "#     wait.until(EC.presence_of_element_located((By.XPATH, '//table//tbody//tr[3]')))\n",
    "#     print(\"Página cargada\")\n",
    "\n",
    "#     # Obtener la fecha del día siguiente\n",
    "#     day = driver.find_elements(By.XPATH, '//table//tbody//tr')[1].text\n",
    "\n",
    "#     time.sleep(5)\n",
    "\n",
    "#     # Copiar los registros\n",
    "#     table = [\n",
    "#         row.text.split('\\n')[0:4] + row.text.split('\\n')[-1].split(' ')\n",
    "#         for row in driver.find_elements(By.XPATH, '//table//tbody//tr')[6::]\n",
    "#     ]\n",
    "\n",
    "#     print(\"Registros extraídos\")\n",
    "\n",
    "#     # Encontrar el índice de la primera sublista que comienza con 'Tomorrow'\n",
    "#     indice_inicio = next(i for i, sublist in enumerate(table) if sublist[0].startswith('Tomorrow'))\n",
    "\n",
    "#     # Seleccionar las 25 sublistas a partir del índice encontrado\n",
    "#     lista_filtrada = table[indice_inicio:indice_inicio + 26]\n",
    "\n",
    "#     columns = ['Hour', 'Condition', 'Temperature', 'Wind', 'Relative_hum', 'Clouds', 'AP', '1']\n",
    "#     mt = pd.DataFrame(lista_filtrada[2:], columns=columns)\n",
    "#     mt.loc[mt['Condition'].str.lower().str.contains('rain'), 'Condition'] = 'Rain'\n",
    "#     mt = mt[['Hour', 'Condition', 'Temperature', 'Wind']]\n",
    "#     mt['Temperature'] = pd.to_numeric(mt['Temperature'].str[:-1])\n",
    "#     mt['Wind'] = pd.to_numeric(mt['Wind'].str[:-5])\n",
    "        \n",
    "    \n",
    "#     # Cerrar el navegador\n",
    "#     driver.quit()\n",
    "\n",
    "#     return mt\n",
    "\n",
    "# URL de Tutiempo\n",
    "\n",
    "\n",
    "# Llamar a la función de scrape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def obtener_fecha_manana():\n",
    "#     # Obtener la fecha actual\n",
    "#     fecha_actual = datetime.now()\n",
    "\n",
    "#     # Calcular la fecha del día siguiente\n",
    "#     fecha_manana = fecha_actual + timedelta(days=1)\n",
    "\n",
    "#     # Formatear la fecha como \"YYYY-MM-DD\"\n",
    "#     formato_fecha = fecha_manana.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#     return formato_fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c43de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_flightera_data():\n",
    "#     # Obtengo fecha del día siguiente\n",
    "#     tomorrow = obtener_fecha_manana()\n",
    "\n",
    "#     url = f'https://www.flightera.net/en/airport/Madrid/LEMD/departure/{tomorrow}%2000_00'\n",
    "    \n",
    "#     table2 = []  # Inicializa table como una lista vacía\n",
    "    \n",
    "#     # Fecha de la URL\n",
    "#     match = re.search(r'\\d{4}-\\d{2}-\\d{2}', url)\n",
    "#     match = match.group()\n",
    "    \n",
    "#     try:\n",
    "#         # Opciones\n",
    "#         opciones = Options()\n",
    "#         opciones.add_extension('drivers/adblock.crx')       # Adblocker\n",
    "#         opciones.add_argument('cookies=cookies')    # Manejo de cookies\n",
    "\n",
    "#         # Inicializo el driver\n",
    "#         driver = webdriver.Chrome(options=opciones)\n",
    "#         driver.get(url)\n",
    "#         wait = WebDriverWait(driver, 20)\n",
    "#         time.sleep(35)\n",
    "\n",
    "#         # Aceptar cookies\n",
    "#         aceptar = driver.find_element(By.XPATH, '//*[@id=\"qc-cmp2-ui\"]/div[2]/div/button[2]')\n",
    "#         aceptar.click()\n",
    "\n",
    "#         # Extraer la información la primera vez\n",
    "#         table2 += [flight.text.split('\\n') for flight in driver.find_elements(By.XPATH, '//table//tbody//tr')[1:]]\n",
    "#         time.sleep(2)\n",
    "\n",
    "#         # Clickar en el botón Later Flights para abrir una nueva URL\n",
    "#         aceptar = wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/main/div[6]/div[2]/a')))\n",
    "#         aceptar.click()\n",
    "#         time.sleep(2)\n",
    "\n",
    "#         # Clickar en boton popup\n",
    "#         aceptar2 = driver.find_element(By.XPATH, '/html/body/div[9]/div/div/div/div/div/div[3]/span[1]/button')\n",
    "#         aceptar2.click()\n",
    "#         time.sleep(2)\n",
    "\n",
    "#         # Extraer la información la primera vez\n",
    "#         table2 += [flight.text.split('\\n') for flight in driver.find_elements(By.XPATH, '//table//tbody//tr')[1:]]\n",
    "#         time.sleep(2)\n",
    "\n",
    "#         aceptar = driver.find_element(By.XPATH, '/html/body/div[2]/main/div[6]/div[2]/a')\n",
    "#         aceptar.click()\n",
    "#         time.sleep(2)\n",
    "\n",
    "#         # Bucle while hasta que la fecha de cada link desaparezca de la URL\n",
    "#         while match in driver.current_url:\n",
    "#             try:\n",
    "#                 # Extraer datos\n",
    "#                 table2 += [flight.text.split('\\n') for flight in driver.find_elements(By.XPATH, '//table//tbody//tr')[1:]]\n",
    "                \n",
    "#                 # Clickar en el botón Later Flights para abrir una nueva URL\n",
    "#                 aceptar = driver.find_element(By.XPATH, '/html/body/div[2]/main/div[6]/div[2]/a')\n",
    "#                 aceptar.click()\n",
    "#             except:\n",
    "#                 # Clickar en boton popup si aparece\n",
    "#                 aceptar2 = driver.find_element(By.XPATH, '/html/body/div[9]/div/div/div/div/div/div[3]/span[1]/button')\n",
    "#                 aceptar2.click()       \n",
    "\n",
    "#     except:\n",
    "#         print(\"Extraction Failed\")\n",
    "#     finally:\n",
    "#         print(\"Extraction completed\")\n",
    "#         driver.quit()\n",
    "\n",
    "#     # Generar el DataFrame\n",
    "#     columns = ['Date', '1', 'Status', 'code', 'airliner', 'mix_data1', 'mix_data2']\n",
    "#     fl = pd.DataFrame(table2, columns=columns)\n",
    "\n",
    "#     # Eliminar nulos\n",
    "#     fl = fl.dropna() \n",
    "\n",
    "#     # Quedarse solo con los vuelos del día de mañana\n",
    "#     fl = fl[fl.Date == fl.Date.loc[0]] \n",
    "\n",
    "#     # Convertir la columna 'Date' al formato de fecha\n",
    "#     fl['Date'] = pd.to_datetime(fl['Date'] + ' 2023', format='%a, %d. %b %Y')\n",
    "\n",
    "#     # Generar la columna 'week_day' con el día de la semana en inglés\n",
    "#     fl['week_day'] = fl['Date'].dt.strftime('%A')\n",
    "\n",
    "#     # Generar la columna 'week_num' con el número de la semana (considerando que los registros son de 2023)\n",
    "#     fl['week_num'] = fl['Date'].dt.strftime('%U')\n",
    "#     fl = fl.drop_duplicates(keep='first')\n",
    "#     fl['code'] = fl['code'].str.split().str[0]\n",
    "\n",
    "#     # Generar columnas con el código de la aerolínea, del aeropuerto y la hora\n",
    "#     fl['cod_airliner_IATA'] = fl['mix_data1'].str.extract(r'(\\b\\w{2})')\n",
    "#     fl['cod_airport_IATA'] = fl['mix_data1'].str.extract(r'\\(\\s*(\\b\\w{3})\\s*/')  # Modificación aquí\n",
    "#     fl['hora'] = fl['mix_data1'].str.extract(r'(\\d{2}:\\d{2})')\n",
    "\n",
    "#     # Aplicar la función a la columna mix_data2 y almacenar los resultados en la columna duration\n",
    "#     fl['duration'] = fl['mix_data2'].apply(obtener_duracion_vuelo)\n",
    "    \n",
    "#     # Redondear la duración total a la unidad de horas\n",
    "#     fl['duration'] = fl['duration'].apply(lambda x: max(round(x / 60), 1))\n",
    "\n",
    "#     # Columnas a eliminar\n",
    "#     columnas_a_eliminar = ['Date', '1', 'airliner', 'mix_data1', 'mix_data2']\n",
    "#     fl = fl.drop(columnas_a_eliminar, axis=1)\n",
    "#     fl = fl.rename(columns={'Status': 'status', 'hora': 'hour', \"code\": \"cod_flight_IATA\"})\n",
    "\n",
    "#     return fl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855fb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def procesar_datos(fl, mt):\n",
    "#     # Renombrar la columna 'Hour' en el DataFrame 'mt'\n",
    "#     mt = mt.rename(columns={'Hour': 'hour'})\n",
    "\n",
    "#     # Convertir las columnas 'hour' a tipo de datos timedelta en ambos DataFrames\n",
    "#     fl['hour'] = pd.to_datetime(fl['hour'], format='%H:%M').dt.time\n",
    "#     mt['hour'] = pd.to_datetime(mt['hour'], format='%H:%M').dt.time\n",
    "\n",
    "#     # Convertir la columna 'hour' a tipo de datos timedelta en ambos DataFrames\n",
    "#     mt['hour'] = pd.to_timedelta(mt['hour'].astype(str))\n",
    "#     fl['hour'] = pd.to_timedelta(fl['hour'].astype(str))\n",
    "\n",
    "#     # Calcular la cantidad total de segundos desde la medianoche\n",
    "#     mt['seconds_since_midnight'] = mt['hour'].dt.total_seconds()\n",
    "#     fl['seconds_since_midnight'] = fl['hour'].dt.total_seconds()\n",
    "\n",
    "#     # Ordenar ambos DataFrames por la columna 'seconds_since_midnight'\n",
    "#     mt = mt.sort_values('seconds_since_midnight')\n",
    "#     fl = fl.sort_values('seconds_since_midnight')\n",
    "\n",
    "#     # Realizar la fusión en la dirección contraria ('backward')\n",
    "#     fl = pd.merge_asof(fl, mt, on='seconds_since_midnight', direction='backward')\n",
    "\n",
    "#     # Eliminar la columna temporal agregada para la fusión\n",
    "#     fl = fl.drop(columns='seconds_since_midnight')\n",
    "\n",
    "#     # Convertir la columna 'hour_x' al formato de tiempo\n",
    "#     fl['hour_x'] = pd.to_timedelta(fl['hour_x'])\n",
    "\n",
    "#     # Extraer solo la parte de la hora\n",
    "#     fl['hour_x'] = fl['hour_x'].apply(lambda x: '{:02}:{:02}:{:02}'.format(int(x.total_seconds() // 3600), int((x.total_seconds() % 3600) // 60), int(x.total_seconds() % 60)))\n",
    "\n",
    "#     # Seleccionar las columnas deseadas y renombrar la columna 'hour_x' a 'hour'\n",
    "#     fl = fl[['status', 'cod_flight_IATA', 'week_day', 'week_num', 'cod_airliner_IATA', 'cod_airport_IATA', 'hour_x', 'duration', 'Condition', 'Temperature', 'Wind']]\n",
    "#     fl = fl.rename(columns={'hour_x': 'hour'})\n",
    "\n",
    "#     # Convertir la columna 'hour' al formato de tiempo\n",
    "#     fl['hour'] = pd.to_datetime(fl['hour'])\n",
    "\n",
    "#     # Crear una nueva columna 'day_time' basada en las horas del día\n",
    "#     fl['day_time'] = pd.cut(fl['hour'].dt.hour, bins=[0, 6, 12, 18, 24], labels=['Early Morning', 'Morning', 'Afternoon', 'Night'], right=False)\n",
    "\n",
    "#     return fl\n",
    "\n",
    "# Llamada a la función con los DataFrames fl y mt como parámetros\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bcbc9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.append('../src')\n",
    "from funpipes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eddac02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed\n",
      "Aceptado normas\n",
      "Aceptadas cookies\n",
      "Página cargada\n",
      "Registros extraídos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>cod_flight_IATA</th>\n",
       "      <th>week_day</th>\n",
       "      <th>week_num</th>\n",
       "      <th>cod_airliner_IATA</th>\n",
       "      <th>cod_airport_IATA</th>\n",
       "      <th>hour</th>\n",
       "      <th>duration</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Wind</th>\n",
       "      <th>day_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On Time</td>\n",
       "      <td>IB6653</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>49</td>\n",
       "      <td>IB</td>\n",
       "      <td>LIM</td>\n",
       "      <td>2023-12-05 00:20:00</td>\n",
       "      <td>12</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Early Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On Time</td>\n",
       "      <td>AV47</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>49</td>\n",
       "      <td>AV</td>\n",
       "      <td>BOG</td>\n",
       "      <td>2023-12-05 00:35:00</td>\n",
       "      <td>10</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Early Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On Time</td>\n",
       "      <td>LA2485</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>49</td>\n",
       "      <td>LA</td>\n",
       "      <td>LIM</td>\n",
       "      <td>2023-12-05 00:55:00</td>\n",
       "      <td>12</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Early Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On Time</td>\n",
       "      <td>EK9390</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>49</td>\n",
       "      <td>EK</td>\n",
       "      <td>DWC</td>\n",
       "      <td>2023-12-05 01:10:00</td>\n",
       "      <td>7</td>\n",
       "      <td>Rain</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Early Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On Time</td>\n",
       "      <td>FR2015</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>49</td>\n",
       "      <td>FR</td>\n",
       "      <td>ACE</td>\n",
       "      <td>2023-12-05 05:45:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Early Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    status cod_flight_IATA   week_day week_num cod_airliner_IATA  \\\n",
       "0  On Time          IB6653  Wednesday       49                IB   \n",
       "1  On Time            AV47  Wednesday       49                AV   \n",
       "2  On Time          LA2485  Wednesday       49                LA   \n",
       "3  On Time          EK9390  Wednesday       49                EK   \n",
       "4  On Time          FR2015  Wednesday       49                FR   \n",
       "\n",
       "  cod_airport_IATA                hour  duration      Condition  Temperature  \\\n",
       "0              LIM 2023-12-05 00:20:00        12         Cloudy            6   \n",
       "1              BOG 2023-12-05 00:35:00        10         Cloudy            6   \n",
       "2              LIM 2023-12-05 00:55:00        12         Cloudy            6   \n",
       "3              DWC 2023-12-05 01:10:00         7           Rain            6   \n",
       "4              ACE 2023-12-05 05:45:00         2  Partly cloudy            5   \n",
       "\n",
       "   Wind       day_time  \n",
       "0     7  Early Morning  \n",
       "1     7  Early Morning  \n",
       "2     7  Early Morning  \n",
       "3     6  Early Morning  \n",
       "4     4  Early Morning  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "fl = procesar_datos(scrape_flightera_data(), scrape_tutiempo_data())\n",
    "fl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c81fd92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 397 entries, 0 to 396\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   status             397 non-null    object        \n",
      " 1   cod_flight_IATA    397 non-null    object        \n",
      " 2   week_day           397 non-null    object        \n",
      " 3   week_num           397 non-null    object        \n",
      " 4   cod_airliner_IATA  397 non-null    object        \n",
      " 5   cod_airport_IATA   397 non-null    object        \n",
      " 6   hour               397 non-null    datetime64[ns]\n",
      " 7   duration           397 non-null    int64         \n",
      " 8   Condition          397 non-null    object        \n",
      " 9   Temperature        397 non-null    int64         \n",
      " 10  Wind               397 non-null    int64         \n",
      " 11  day_time           397 non-null    category      \n",
      "dtypes: category(1), datetime64[ns](1), int64(3), object(7)\n",
      "memory usage: 37.8+ KB\n"
     ]
    }
   ],
   "source": [
    "fl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe5371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaffc85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf334eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d8e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356054f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d7902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba8a1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90e92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018edce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eff468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1322c903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef6b75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861d85c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5105d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c10ce91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6cfce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d90b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a783e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #driver configuration\n",
    "# opciones=Options()\n",
    "\n",
    "# opciones.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "# opciones.add_experimental_option('useAutomationExtension', False)\n",
    "# opciones.headless=False    # si True, no aperece la ventana (headless=no visible)\n",
    "# opciones.add_argument('--start-maximized')         # comienza maximizado\n",
    "# opciones.add_argument('--incognito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd70ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://en.tutiempo.net/madrid-barajas.html?data=hourly&v=list'\n",
    "\n",
    "# driver = webdriver.Chrome()\n",
    "# driver.get(url)\n",
    "# wait = WebDriverWait(driver, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53aee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Options\n",
    "# opciones=Options()\n",
    "# opciones.add_extension('drivers/adblock.crx')       # adblocker\n",
    "# opciones.add_argument('cookies=cookies')    # man\n",
    "\n",
    "# flights =[]\n",
    "# table = []\n",
    "\n",
    "# driver = webdriver.Chrome(options=opciones)\n",
    "# driver.get(url)\n",
    "# wait = WebDriverWait(driver, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0994f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aceptar = driver.find_element(By.XPATH,'//*[@id=\"qc-cmp2-ui\"]/div[2]/div/button[2]')\n",
    "# aceptar.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee67be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aceptar = wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/main/div[6]/div[2]/a')))\n",
    "# aceptar.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181f308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aceptar2 = driver.find_element(By.XPATH, '/html/body/div[9]/div/div/div/div/div/div[3]/span[1]/button')\n",
    "# aceptar2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc90b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Options\n",
    "# opciones=Options()\n",
    "# opciones.add_extension('drivers/adblock.crx')       # adblocker\n",
    "# opciones.add_argument('cookies=cookies')    # man\n",
    "\n",
    "# flights =[]\n",
    "# table = []\n",
    "\n",
    "# driver = webdriver.Chrome(options=opciones)\n",
    "# driver.get(url)\n",
    "# wait = WebDriverWait(driver, 20)\n",
    "# time.sleep(20) #35\n",
    "# aceptar = driver.find_element(By.XPATH,'//*[@id=\"qc-cmp2-ui\"]/div[2]/div/button[2]')\n",
    "# aceptar.click()\n",
    "# time.sleep(5) \n",
    "\n",
    "# # Extraer la información la primera vez\n",
    "# table += [flight.text.split('\\n') for flight in driver.find_elements(By.XPATH, '//table//tbody//tr')[1:]]\n",
    "# time.sleep(4)\n",
    "\n",
    "# # Clickar en el botón Later Flights para abrir una nueva URL\n",
    "# aceptar = wait.until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/main/div[6]/div[2]/a')))\n",
    "#         #aceptar = driver.find_element(By.XPATH, '/html/body/div[3]/main/div[6]/div[2]/a')\n",
    "# aceptar.click()\n",
    "# time.sleep(4)\n",
    "\n",
    "# aceptar2 = driver.find_element(By.XPATH, '/html/body/div[9]/div/div/div/div/div/div[3]/span[1]/button')\n",
    "# aceptar2.click()\n",
    "# time.sleep(2)\n",
    "# table += [flight.text.split('\\n') for flight in driver.find_elements(By.XPATH, '//table//tbody//tr')[1:]]\n",
    "# time.sleep(2)\n",
    "# driver.quit()\n",
    "# table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0bd059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60257014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a28f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf7d26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a25bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4ceaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f50de4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc307e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758218c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb4039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73219f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15859fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0b5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
